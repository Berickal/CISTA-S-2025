{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP : Natural Language Processing (NLP) avec Transformers\n",
    "\n",
    "## Objectifs\n",
    "- Comprendre l'architecture des Transformers et leur importance en NLP\n",
    "- Utiliser des modèles pré-entraînés (BERT, DistilBERT, etc.) avec Hugging Face\n",
    "- Fine-tuner des transformers pour des tâches spécifiques\n",
    "- Implémenter des applications NLP : analyse de sentiment, classification de texte\n",
    "- Comparer les transformers avec les approches classiques (RNN, LSTM)\n",
    "- Comprendre les concepts de tokenization, attention, et embeddings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports et Configuration\n",
    "\n",
    "Importation des bibliothèques nécessaires pour travailler avec les transformers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformers et NLP\n",
    "from transformers import (\n",
    "    AutoTokenizer, AutoModel, AutoModelForSequenceClassification,\n",
    "    pipeline, Trainer, TrainingArguments,\n",
    "    BertTokenizer, BertModel,\n",
    "    DistilBertTokenizer, DistilBertForSequenceClassification\n",
    ")\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "# Deep Learning\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Utilities\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuration\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "torch.manual_seed(RANDOM_STATE)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(RANDOM_STATE)\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "# Style pour les graphiques\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"Device: {device}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Introduction aux Transformers\n",
    "\n",
    "### 2.1. Concepts Fondamentaux\n",
    "\n",
    "Les **Transformers** ont révolutionné le NLP moderne avec l'introduction du mécanisme d'**Attention**.\n",
    "\n",
    "**Architecture Transformer :**\n",
    "- **Encoder-Decoder** : Architecture originale (traduction)\n",
    "- **Encoder-only** : BERT, DistilBERT (compréhension du langage)\n",
    "- **Decoder-only** : GPT (génération de texte)\n",
    "\n",
    "**Composants clés :**\n",
    "1. **Self-Attention** : Permet au modèle de se concentrer sur différentes parties de l'input\n",
    "2. **Multi-Head Attention** : Plusieurs têtes d'attention en parallèle\n",
    "3. **Feed-Forward Networks** : Réseaux fully connected\n",
    "4. **Layer Normalization** : Stabilisation de l'entraînement\n",
    "5. **Positional Encoding** : Encodage de la position des mots\n",
    "\n",
    "**Avantages des Transformers :**\n",
    "- Parallélisation (vs RNN séquentiels)\n",
    "- Long-range dependencies (meilleur que RNN/LSTM)\n",
    "- Modèles pré-entraînés puissants (BERT, GPT, etc.)\n",
    "- Transfer learning efficace\n",
    "\n",
    "### 2.2. Modèles Pré-entraînés Populaires\n",
    "\n",
    "- **BERT** (Bidirectional Encoder Representations from Transformers) : Compréhension bidirectionnelle\n",
    "- **DistilBERT** : Version légère et rapide de BERT\n",
    "- **RoBERTa** : Optimisation de BERT\n",
    "- **GPT** : Génération de texte\n",
    "- **T5** : Text-to-Text Transfer Transformer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Chargement et Préparation des Données\n",
    "\n",
    "### 3.1. Dataset d'Analyse de Sentiment\n",
    "\n",
    "Nous utiliserons un dataset d'analyse de sentiment pour démontrer l'utilisation des transformers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1: Utiliser un dataset depuis Hugging Face datasets\n",
    "try:\n",
    "    from datasets import load_dataset\n",
    "    print(\"Chargement du dataset IMDB depuis Hugging Face...\")\n",
    "    dataset = load_dataset(\"imdb\", split=\"train[:5000]+test[:1000]\")  # Échantillon pour la démo\n",
    "    df = dataset.to_pandas()\n",
    "    df = df[['text', 'label']]\n",
    "    df.columns = ['text', 'sentiment']\n",
    "    print(f\"Dataset chargé: {len(df)} échantillons\")\n",
    "    DATASET_LOADED = True\n",
    "except Exception as e:\n",
    "    print(f\"Impossible de charger depuis Hugging Face: {e}\")\n",
    "    print(\"Création d'un dataset d'exemple...\")\n",
    "    # Dataset d'exemple simple\n",
    "    texts = [\n",
    "        \"This movie is absolutely fantastic! I loved every minute of it.\",\n",
    "        \"Terrible film, complete waste of time. Boring and poorly acted.\",\n",
    "        \"Great acting and a compelling storyline. Highly recommended!\",\n",
    "        \"The worst movie I've ever seen. Plot makes no sense.\",\n",
    "        \"Excellent cinematography and brilliant performances.\",\n",
    "        \"I found this movie quite boring and predictable.\",\n",
    "        \"Outstanding! One of the best films this year.\",\n",
    "        \"Poor direction and bad script. Very disappointed.\",\n",
    "    ] * 100  # Répéter pour avoir plus de données\n",
    "    labels = [1, 0, 1, 0, 1, 0, 1, 0] * 100\n",
    "    df = pd.DataFrame({'text': texts, 'sentiment': labels})\n",
    "    DATASET_LOADED = False\n",
    "\n",
    "# Afficher quelques exemples\n",
    "print(\"\\nPremiers exemples du dataset:\")\n",
    "print(df.head(10))\n",
    "print(f\"\\nDistribution des sentiments:\")\n",
    "print(df['sentiment'].value_counts())\n",
    "print(f\"\\nExemples de textes:\")\n",
    "for i in range(3):\n",
    "    print(f\"\\n{i+1}. Sentiment: {df.iloc[i]['sentiment']} (1=positif, 0=négatif)\")\n",
    "    print(f\"   Texte: {df.iloc[i]['text'][:100]}...\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Préparation des Données\n",
    "\n",
    "Division en ensembles d'entraînement, validation et test.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Division train/validation/test\n",
    "train_texts, temp_texts, train_labels, temp_labels = train_test_split(\n",
    "    df['text'].values, df['sentiment'].values, \n",
    "    test_size=0.3, random_state=RANDOM_STATE, stratify=df['sentiment']\n",
    ")\n",
    "\n",
    "val_texts, test_texts, val_labels, test_labels = train_test_split(\n",
    "    temp_texts, temp_labels, \n",
    "    test_size=0.5, random_state=RANDOM_STATE, stratify=temp_labels\n",
    ")\n",
    "\n",
    "print(f\"Train set: {len(train_texts)} échantillons\")\n",
    "print(f\"Validation set: {len(val_texts)} échantillons\")\n",
    "print(f\"Test set: {len(test_texts)} échantillons\")\n",
    "print(f\"\\nDistribution des sentiments (train):\")\n",
    "print(pd.Series(train_labels).value_counts().sort_index())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Utilisation des Transformers avec Hugging Face\n",
    "\n",
    "### 4.1. Pipeline Simple (Zero-Shot Classification)\n",
    "\n",
    "La façon la plus simple d'utiliser les transformers est via les **pipelines** de Hugging Face.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline pour l'analyse de sentiment (pré-entraîné)\n",
    "print(\"Chargement du pipeline d'analyse de sentiment...\")\n",
    "sentiment_pipeline = pipeline(\"sentiment-analysis\", device=0 if torch.cuda.is_available() else -1)\n",
    "\n",
    "# Tester sur quelques exemples\n",
    "test_sentences = [\n",
    "    \"I love this movie! It's fantastic!\",\n",
    "    \"This is the worst film I've ever seen.\",\n",
    "    \"The movie was okay, nothing special.\",\n",
    "    \"Brilliant acting and excellent cinematography!\"\n",
    "]\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ANALYSE DE SENTIMENT AVEC PIPELINE\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for sentence in test_sentences:\n",
    "    result = sentiment_pipeline(sentence)[0]\n",
    "    print(f\"\\nTexte: {sentence}\")\n",
    "    print(f\"Label: {result['label']}\")\n",
    "    print(f\"Score: {result['score']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Tokenization avec BERT\n",
    "\n",
    "La tokenization est cruciale pour les transformers. Explorons comment BERT tokenise le texte.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger le tokenizer BERT\n",
    "print(\"Chargement du tokenizer BERT...\")\n",
    "model_name = \"bert-base-uncased\"\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Exemple de tokenization\n",
    "sample_text = \"I love transformers and deep learning!\"\n",
    "print(f\"\\nTexte original: {sample_text}\")\n",
    "print(f\"Longueur du texte: {len(sample_text.split())} mots\")\n",
    "\n",
    "# Tokenization\n",
    "tokens = tokenizer.tokenize(sample_text)\n",
    "token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "encoded = tokenizer.encode(sample_text, add_special_tokens=True)\n",
    "\n",
    "print(f\"\\nTokens: {tokens}\")\n",
    "print(f\"Nombre de tokens: {len(tokens)}\")\n",
    "print(f\"\\nToken IDs: {token_ids}\")\n",
    "print(f\"\\nEncodage complet (avec [CLS] et [SEP]): {encoded}\")\n",
    "print(f\"Longueur encodée: {len(encoded)}\")\n",
    "\n",
    "# Décodage\n",
    "decoded = tokenizer.decode(encoded)\n",
    "print(f\"\\nDécodé: {decoded}\")\n",
    "\n",
    "# Visualisation des tokens spéciaux\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TOKENS SPÉCIAUX BERT\")\n",
    "print(\"=\"*70)\n",
    "print(f\"[CLS]: {tokenizer.cls_token_id} (début de séquence)\")\n",
    "print(f\"[SEP]: {tokenizer.sep_token_id} (fin de séquence)\")\n",
    "print(f\"[PAD]: {tokenizer.pad_token_id} (padding)\")\n",
    "print(f\"[UNK]: {tokenizer.unk_token_id} (token inconnu)\")\n",
    "\n",
    "# Tokenization d'un batch avec padding et truncation\n",
    "texts_batch = [\n",
    "    \"This is a short text.\",\n",
    "    \"This is a much longer text that needs to be handled properly with padding and truncation to fit the model's requirements.\"\n",
    "]\n",
    "\n",
    "encoded_batch = tokenizer(\n",
    "    texts_batch,\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    max_length=128,\n",
    "    return_tensors=\"pt\"\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TOKENIZATION DE BATCH\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Input IDs shape: {encoded_batch['input_ids'].shape}\")\n",
    "print(f\"Attention mask shape: {encoded_batch['attention_mask'].shape}\")\n",
    "print(f\"\\nInput IDs:\")\n",
    "print(encoded_batch['input_ids'])\n",
    "print(f\"\\nAttention mask (1 = vrai token, 0 = padding):\")\n",
    "print(encoded_batch['attention_mask'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Fine-tuning d'un Transformer pour Classification\n",
    "\n",
    "### 5.1. Création d'un Dataset Personnalisé\n",
    "\n",
    "Créons une classe Dataset pour gérer nos données efficacement.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentDataset(Dataset):\n",
    "    \"\"\"Dataset personnalisé pour l'analyse de sentiment\"\"\"\n",
    "    \n",
    "    def __init__(self, texts, labels, tokenizer, max_length=128):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        # Tokenization\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=self.max_length,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'label': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "# Utiliser DistilBERT (plus léger et rapide que BERT)\n",
    "print(\"Chargement de DistilBERT...\")\n",
    "model_name = \"distilbert-base-uncased\"\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Créer les datasets\n",
    "train_dataset = SentimentDataset(train_texts, train_labels, tokenizer)\n",
    "val_dataset = SentimentDataset(val_texts, val_labels, tokenizer)\n",
    "test_dataset = SentimentDataset(test_texts, test_labels, tokenizer)\n",
    "\n",
    "print(f\"\\nTrain dataset: {len(train_dataset)} échantillons\")\n",
    "print(f\"Validation dataset: {len(val_dataset)} échantillons\")\n",
    "print(f\"Test dataset: {len(test_dataset)} échantillons\")\n",
    "\n",
    "# Visualiser un exemple\n",
    "sample = train_dataset[0]\n",
    "print(f\"\\nExemple du dataset:\")\n",
    "print(f\"Input IDs shape: {sample['input_ids'].shape}\")\n",
    "print(f\"Attention mask shape: {sample['attention_mask'].shape}\")\n",
    "print(f\"Label: {sample['label'].item()}\")\n",
    "print(f\"Texte original: {train_texts[0][:100]}...\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2. Chargement du Modèle Pré-entraîné\n",
    "\n",
    "Chargeons DistilBERT pour la classification de séquences.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger le modèle pré-entraîné pour classification\n",
    "num_labels = 2  # Classification binaire (positif/négatif)\n",
    "\n",
    "model = DistilBertForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=num_labels\n",
    ")\n",
    "\n",
    "model = model.to(device)\n",
    "print(f\"Modèle chargé sur {device}\")\n",
    "print(f\"Nombre de paramètres: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "\n",
    "# Afficher l'architecture du modèle\n",
    "print(\"\\nArchitecture du modèle:\")\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3. Fonction d'Entraînement\n",
    "\n",
    "Créons les fonctions nécessaires pour l'entraînement.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration de l'entraînement\n",
    "BATCH_SIZE = 16\n",
    "LEARNING_RATE = 2e-5\n",
    "NUM_EPOCHS = 3\n",
    "\n",
    "# DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# Optimizer et scheduler\n",
    "optimizer = AdamW(model.parameters(), lr=LEARNING_RATE)\n",
    "total_steps = len(train_loader) * NUM_EPOCHS\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=total_steps\n",
    ")\n",
    "\n",
    "print(f\"Batch size: {BATCH_SIZE}\")\n",
    "print(f\"Learning rate: {LEARNING_RATE}\")\n",
    "print(f\"Nombre d'epochs: {NUM_EPOCHS}\")\n",
    "print(f\"Total steps: {total_steps}\")\n",
    "print(f\"Train batches: {len(train_loader)}\")\n",
    "print(f\"Validation batches: {len(val_loader)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, dataloader, optimizer, scheduler, device):\n",
    "    \"\"\"Entraîne le modèle pour une époque\"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "    \n",
    "    for batch in dataloader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            labels=labels\n",
    "        )\n",
    "        \n",
    "        loss = outputs.loss\n",
    "        logits = outputs.logits\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Métriques\n",
    "        total_loss += loss.item()\n",
    "        predictions = torch.argmax(logits, dim=1)\n",
    "        correct_predictions += torch.sum(predictions == labels)\n",
    "        total_samples += labels.size(0)\n",
    "    \n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    accuracy = correct_predictions.double() / total_samples\n",
    "    \n",
    "    return avg_loss, accuracy.item()\n",
    "\n",
    "def eval_model(model, dataloader, device):\n",
    "    \"\"\"Évalue le modèle\"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "            \n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                labels=labels\n",
    "            )\n",
    "            \n",
    "            loss = outputs.loss\n",
    "            logits = outputs.logits\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            predictions = torch.argmax(logits, dim=1)\n",
    "            correct_predictions += torch.sum(predictions == labels)\n",
    "            total_samples += labels.size(0)\n",
    "            \n",
    "            all_predictions.extend(predictions.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    accuracy = correct_predictions.double() / total_samples\n",
    "    \n",
    "    return avg_loss, accuracy.item(), all_predictions, all_labels\n",
    "\n",
    "print(\"Fonctions d'entraînement et d'évaluation définies.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4. Entraînement du Modèle\n",
    "\n",
    "Lançons l'entraînement du modèle.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Historique de l'entraînement\n",
    "history = {\n",
    "    'train_loss': [],\n",
    "    'train_acc': [],\n",
    "    'val_loss': [],\n",
    "    'val_acc': []\n",
    "}\n",
    "\n",
    "print(\"Démarrage de l'entraînement...\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    print(f\"\\nEpoch {epoch + 1}/{NUM_EPOCHS}\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    # Entraînement\n",
    "    train_loss, train_acc = train_epoch(model, train_loader, optimizer, scheduler, device)\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['train_acc'].append(train_acc)\n",
    "    \n",
    "    # Validation\n",
    "    val_loss, val_acc, _, _ = eval_model(model, val_loader, device)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_acc'].append(val_acc)\n",
    "    \n",
    "    print(f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f}\")\n",
    "    print(f\"Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Entraînement terminé!\")\n",
    "print(\"=\"*70)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5. Visualisation de l'Entraînement\n",
    "\n",
    "Visualisons les courbes d'apprentissage.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation de l'historique\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Loss\n",
    "axes[0].plot(history['train_loss'], label='Train Loss', linewidth=2, marker='o')\n",
    "axes[0].plot(history['val_loss'], label='Validation Loss', linewidth=2, marker='s')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Loss')\n",
    "axes[0].set_title('Training and Validation Loss', fontsize=14, fontweight='bold')\n",
    "axes[0].legend()\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "# Accuracy\n",
    "axes[1].plot(history['train_acc'], label='Train Accuracy', linewidth=2, marker='o')\n",
    "axes[1].plot(history['val_acc'], label='Validation Accuracy', linewidth=2, marker='s')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Accuracy')\n",
    "axes[1].set_title('Training and Validation Accuracy', fontsize=14, fontweight='bold')\n",
    "axes[1].legend()\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Meilleure validation accuracy: {max(history['val_acc']):.4f}\")\n",
    "print(f\"Meilleure validation loss: {min(history['val_loss']):.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Évaluation du Modèle\n",
    "\n",
    "Évaluons les performances sur le set de test.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Évaluation sur le test set\n",
    "test_loss, test_acc, test_predictions, test_labels = eval_model(model, test_loader, device)\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"ÉVALUATION SUR LE TEST SET\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {test_acc:.4f} ({test_acc*100:.2f}%)\")\n",
    "\n",
    "# Rapport de classification\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"RAPPORT DE CLASSIFICATION\")\n",
    "print(\"=\"*70)\n",
    "print(classification_report(test_labels, test_predictions, \n",
    "                          target_names=['Négatif', 'Positif']))\n",
    "\n",
    "# Matrice de confusion\n",
    "cm = confusion_matrix(test_labels, test_predictions)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Négatif', 'Positif'],\n",
    "            yticklabels=['Négatif', 'Positif'])\n",
    "plt.title('Matrice de Confusion - DistilBERT Fine-tuned', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('Vraie classe')\n",
    "plt.xlabel('Classe prédite')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Prédictions sur Nouvelles Phrases\n",
    "\n",
    "Testons le modèle fine-tuné sur de nouvelles phrases.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentiment(text, model, tokenizer, device):\n",
    "    \"\"\"Prédit le sentiment d'un texte\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Tokenization\n",
    "    encoding = tokenizer(\n",
    "        text,\n",
    "        truncation=True,\n",
    "        padding='max_length',\n",
    "        max_length=128,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    \n",
    "    input_ids = encoding['input_ids'].to(device)\n",
    "    attention_mask = encoding['attention_mask'].to(device)\n",
    "    \n",
    "    # Prédiction\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "        probabilities = torch.softmax(logits, dim=1)\n",
    "        prediction = torch.argmax(logits, dim=1)\n",
    "    \n",
    "    sentiment = \"Positif\" if prediction.item() == 1 else \"Négatif\"\n",
    "    confidence = probabilities[0][prediction.item()].item()\n",
    "    \n",
    "    return sentiment, confidence, probabilities[0].cpu().numpy()\n",
    "\n",
    "# Tester sur de nouvelles phrases\n",
    "new_texts = [\n",
    "    \"This movie is absolutely amazing! Best film I've seen this year.\",\n",
    "    \"Terrible experience. Poor acting and a boring plot.\",\n",
    "    \"It was okay, nothing special but not bad either.\",\n",
    "    \"Outstanding performance by all actors. Highly recommended!\",\n",
    "    \"Waste of time and money. Very disappointed.\",\n",
    "    \"Brilliant cinematography and excellent storytelling.\",\n",
    "]\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"PRÉDICTIONS SUR DE NOUVELLES PHRASES\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for text in new_texts:\n",
    "    sentiment, confidence, probs = predict_sentiment(text, model, tokenizer, device)\n",
    "    print(f\"\\nTexte: {text}\")\n",
    "    print(f\"Sentiment prédit: {sentiment} (Confiance: {confidence:.4f})\")\n",
    "    print(f\"Probabilités: Négatif={probs[0]:.4f}, Positif={probs[1]:.4f}\")\n",
    "    print(\"-\" * 70)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Comparaison avec Approches Classiques\n",
    "\n",
    "Comparons les transformers avec des approches classiques (TF-IDF + Logistic Regression).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Approche classique : TF-IDF + Logistic Regression\n",
    "print(\"Entraînement d'un modèle classique (TF-IDF + Logistic Regression)...\")\n",
    "\n",
    "# TF-IDF Vectorization\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000, ngram_range=(1, 2))\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(train_texts)\n",
    "X_val_tfidf = tfidf_vectorizer.transform(val_texts)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(test_texts)\n",
    "\n",
    "# Logistic Regression\n",
    "lr_model = LogisticRegression(random_state=RANDOM_STATE, max_iter=1000)\n",
    "lr_model.fit(X_train_tfidf, train_labels)\n",
    "\n",
    "# Prédictions\n",
    "train_pred_lr = lr_model.predict(X_train_tfidf)\n",
    "val_pred_lr = lr_model.predict(X_val_tfidf)\n",
    "test_pred_lr = lr_model.predict(X_test_tfidf)\n",
    "\n",
    "# Métriques\n",
    "train_acc_lr = accuracy_score(train_labels, train_pred_lr)\n",
    "val_acc_lr = accuracy_score(val_labels, val_pred_lr)\n",
    "test_acc_lr = accuracy_score(test_labels, test_pred_lr)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"COMPARAISON DES MÉTHODES\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nTF-IDF + Logistic Regression:\")\n",
    "print(f\"  Train Accuracy: {train_acc_lr:.4f} ({train_acc_lr*100:.2f}%)\")\n",
    "print(f\"  Validation Accuracy: {val_acc_lr:.4f} ({val_acc_lr*100:.2f}%)\")\n",
    "print(f\"  Test Accuracy: {test_acc_lr:.4f} ({test_acc_lr*100:.2f}%)\")\n",
    "\n",
    "print(f\"\\nDistilBERT Fine-tuned:\")\n",
    "print(f\"  Train Accuracy: {history['train_acc'][-1]:.4f} ({history['train_acc'][-1]*100:.2f}%)\")\n",
    "print(f\"  Validation Accuracy: {history['val_acc'][-1]:.4f} ({history['val_acc'][-1]*100:.2f}%)\")\n",
    "print(f\"  Test Accuracy: {test_acc:.4f} ({test_acc*100:.2f}%)\")\n",
    "\n",
    "# Visualisation\n",
    "comparison_data = {\n",
    "    'Méthode': ['TF-IDF + LR', 'TF-IDF + LR', 'TF-IDF + LR', 'DistilBERT', 'DistilBERT', 'DistilBERT'],\n",
    "    'Set': ['Train', 'Validation', 'Test', 'Train', 'Validation', 'Test'],\n",
    "    'Accuracy': [train_acc_lr, val_acc_lr, test_acc_lr, \n",
    "                 history['train_acc'][-1], history['val_acc'][-1], test_acc]\n",
    "}\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "x = np.arange(3)\n",
    "width = 0.35\n",
    "\n",
    "methods = ['TF-IDF + LR', 'DistilBERT']\n",
    "train_accs = [train_acc_lr, history['train_acc'][-1]]\n",
    "val_accs = [val_acc_lr, history['val_acc'][-1]]\n",
    "test_accs = [test_acc_lr, test_acc]\n",
    "\n",
    "x_pos = np.arange(len(methods))\n",
    "width = 0.25\n",
    "\n",
    "ax.bar(x_pos - width, train_accs, width, label='Train', alpha=0.8)\n",
    "ax.bar(x_pos, val_accs, width, label='Validation', alpha=0.8)\n",
    "ax.bar(x_pos + width, test_accs, width, label='Test', alpha=0.8)\n",
    "\n",
    "ax.set_xlabel('Méthode', fontsize=12)\n",
    "ax.set_ylabel('Accuracy', fontsize=12)\n",
    "ax.set_title('Comparaison des Performances', fontsize=14, fontweight='bold')\n",
    "ax.set_xticks(x_pos)\n",
    "ax.set_xticklabels(methods)\n",
    "ax.legend()\n",
    "ax.grid(alpha=0.3, axis='y')\n",
    "ax.set_ylim([0, 1.1])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Extraction d'Embeddings et Visualisation\n",
    "\n",
    "Visualisons les embeddings extraits du modèle BERT pour comprendre comment il représente le texte.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger BERT pour extraction d'embeddings\n",
    "bert_model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "bert_tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "bert_model = bert_model.to(device)\n",
    "bert_model.eval()\n",
    "\n",
    "def extract_embeddings(texts, model, tokenizer, device, max_length=128):\n",
    "    \"\"\"Extrait les embeddings de [CLS] token\"\"\"\n",
    "    embeddings = []\n",
    "    \n",
    "    for text in texts:\n",
    "        encoding = tokenizer(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=max_length,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        input_ids = encoding['input_ids'].to(device)\n",
    "        attention_mask = encoding['attention_mask'].to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            # Utiliser le token [CLS] (premier token)\n",
    "            cls_embedding = outputs.last_hidden_state[:, 0, :].cpu().numpy()\n",
    "            embeddings.append(cls_embedding[0])\n",
    "    \n",
    "    return np.array(embeddings)\n",
    "\n",
    "# Extraire les embeddings pour quelques exemples\n",
    "sample_texts = [\n",
    "    \"I love this movie!\",\n",
    "    \"This film is terrible.\",\n",
    "    \"Great acting and story.\",\n",
    "    \"Boring and predictable.\",\n",
    "    \"Excellent cinematography!\",\n",
    "    \"Waste of time.\"\n",
    "]\n",
    "sample_labels = [1, 0, 1, 0, 1, 0]\n",
    "\n",
    "print(\"Extraction des embeddings BERT...\")\n",
    "embeddings = extract_embeddings(sample_texts, bert_model, bert_tokenizer, device)\n",
    "\n",
    "print(f\"Shape des embeddings: {embeddings.shape}\")\n",
    "\n",
    "# Réduction de dimensionnalité avec PCA pour visualisation\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "embeddings_2d = pca.fit_transform(embeddings)\n",
    "\n",
    "# Visualisation\n",
    "plt.figure(figsize=(10, 8))\n",
    "colors = ['green' if label == 1 else 'red' for label in sample_labels]\n",
    "scatter = plt.scatter(embeddings_2d[:, 0], embeddings_2d[:, 1], c=colors, s=100, alpha=0.7, edgecolors='black')\n",
    "\n",
    "for i, text in enumerate(sample_texts):\n",
    "    plt.annotate(text[:20] + '...', (embeddings_2d[i, 0], embeddings_2d[i, 1]), \n",
    "                fontsize=9, alpha=0.7)\n",
    "\n",
    "plt.xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.2%} variance)', fontsize=12)\n",
    "plt.ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.2%} variance)', fontsize=12)\n",
    "plt.title('Visualisation des Embeddings BERT (PCA)', fontsize=14, fontweight='bold')\n",
    "plt.grid(alpha=0.3)\n",
    "plt.legend(handles=[\n",
    "    plt.Line2D([0], [0], marker='o', color='w', markerfacecolor='green', markersize=10, label='Positif'),\n",
    "    plt.Line2D([0], [0], marker='o', color='w', markerfacecolor='red', markersize=10, label='Négatif')\n",
    "])\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Utilisation de Modèles Pré-entraînés (Sans Fine-tuning)\n",
    "\n",
    "Explorons comment utiliser des modèles pré-entraînés directement sans fine-tuning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline pré-entraîné pour sentiment analysis\n",
    "print(\"Test avec pipeline pré-entraîné (sans fine-tuning)...\")\n",
    "pretrained_pipeline = pipeline(\n",
    "    \"sentiment-analysis\",\n",
    "    model=\"distilbert-base-uncased-finetuned-sst-2-english\",\n",
    "    device=0 if torch.cuda.is_available() else -1\n",
    ")\n",
    "\n",
    "# Tester sur quelques phrases du test set\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"COMPARAISON: PRÉ-ENTRAÎNÉ vs FINE-TUNÉ\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "test_samples = test_texts[:10]\n",
    "test_true_labels = test_labels[:10]\n",
    "\n",
    "for i, (text, true_label) in enumerate(zip(test_samples, test_true_labels)):\n",
    "    # Pré-entraîné\n",
    "    pretrained_result = pretrained_pipeline(text[:512])[0]  # Limiter la longueur\n",
    "    pretrained_label = 1 if pretrained_result['label'] == 'POSITIVE' else 0\n",
    "    \n",
    "    # Fine-tuné\n",
    "    fine_tuned_sentiment, fine_tuned_conf, _ = predict_sentiment(text, model, tokenizer, device)\n",
    "    fine_tuned_label = 1 if fine_tuned_sentiment == \"Positif\" else 0\n",
    "    \n",
    "    print(f\"\\n{i+1}. Texte: {text[:80]}...\")\n",
    "    print(f\"   Vrai label: {'Positif' if true_label == 1 else 'Négatif'}\")\n",
    "    print(f\"   Pré-entraîné: {pretrained_result['label']} ({pretrained_result['score']:.3f}) - {'✓' if pretrained_label == true_label else '✗'}\")\n",
    "    print(f\"   Fine-tuné: {fine_tuned_sentiment} ({fine_tuned_conf:.3f}) - {'✓' if fine_tuned_label == true_label else '✗'}\")\n",
    "    print(\"-\" * 70)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Autres Applications des Transformers\n",
    "\n",
    "### 11.1. Zero-Shot Classification\n",
    "\n",
    "Les transformers peuvent classifier du texte dans des catégories sans entraînement spécifique.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zero-shot classification\n",
    "try:\n",
    "    classifier = pipeline(\"zero-shot-classification\", device=0 if torch.cuda.is_available() else -1)\n",
    "    \n",
    "    text_to_classify = \"The movie had excellent acting and a compelling story.\"\n",
    "    candidate_labels = [\"positive\", \"negative\", \"neutral\", \"exciting\", \"boring\"]\n",
    "    \n",
    "    result = classifier(text_to_classify, candidate_labels)\n",
    "    \n",
    "    print(\"=\"*70)\n",
    "    print(\"ZERO-SHOT CLASSIFICATION\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"Texte: {text_to_classify}\")\n",
    "    print(f\"\\nCatégories candidates: {candidate_labels}\")\n",
    "    print(f\"\\nRésultats:\")\n",
    "    for label, score in zip(result['labels'], result['scores']):\n",
    "        print(f\"  {label}: {score:.4f}\")\n",
    "    \n",
    "    # Visualisation\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    y_pos = np.arange(len(result['labels']))\n",
    "    plt.barh(y_pos, result['scores'], alpha=0.7, color='steelblue')\n",
    "    plt.yticks(y_pos, result['labels'])\n",
    "    plt.xlabel('Score de confiance', fontsize=12)\n",
    "    plt.title('Zero-Shot Classification', fontsize=14, fontweight='bold')\n",
    "    plt.grid(alpha=0.3, axis='x')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Zero-shot classification non disponible: {e}\")\n",
    "    print(\"Cette fonctionnalité nécessite un modèle spécifique (ex: facebook/bart-large-mnli)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.2. Question Answering (Réponse aux Questions)\n",
    "\n",
    "Les transformers peuvent répondre à des questions basées sur un contexte.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question Answering\n",
    "try:\n",
    "    qa_pipeline = pipeline(\"question-answering\", device=0 if torch.cuda.is_available() else -1)\n",
    "    \n",
    "    context = \"\"\"\n",
    "    Transformers are deep learning models that have revolutionized natural language processing.\n",
    "    They use attention mechanisms to process sequences of text. BERT, GPT, and T5 are popular\n",
    "    transformer models. BERT is bidirectional and great for understanding, while GPT is\n",
    "    unidirectional and excellent for text generation.\n",
    "    \"\"\"\n",
    "    \n",
    "    questions = [\n",
    "        \"What are transformers?\",\n",
    "        \"Which transformer is good for text generation?\",\n",
    "        \"What mechanism do transformers use?\"\n",
    "    ]\n",
    "    \n",
    "    print(\"=\"*70)\n",
    "    print(\"QUESTION ANSWERING\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"Contexte:\\n{context.strip()}\\n\")\n",
    "    \n",
    "    for question in questions:\n",
    "        result = qa_pipeline(question=question, context=context)\n",
    "        print(f\"Question: {question}\")\n",
    "        print(f\"Réponse: {result['answer']}\")\n",
    "        print(f\"Score: {result['score']:.4f}\")\n",
    "        print(\"-\" * 70)\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Question answering non disponible: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Sauvegarde et Chargement du Modèle\n",
    "\n",
    "Sauvegardons notre modèle fine-tuné pour une utilisation ultérieure.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sauvegarder le modèle et le tokenizer\n",
    "save_directory = \"./sentiment_model\"\n",
    "model.save_pretrained(save_directory)\n",
    "tokenizer.save_pretrained(save_directory)\n",
    "\n",
    "print(f\"Modèle sauvegardé dans: {save_directory}\")\n",
    "\n",
    "# Pour charger le modèle plus tard:\n",
    "# from transformers import DistilBertForSequenceClassification, DistilBertTokenizer\n",
    "# loaded_model = DistilBertForSequenceClassification.from_pretrained(save_directory)\n",
    "# loaded_tokenizer = DistilBertTokenizer.from_pretrained(save_directory)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Résumé et Conclusions\n",
    "\n",
    "### 13.1. Avantages des Transformers\n",
    "\n",
    "**Par rapport aux approches classiques (TF-IDF, RNN, LSTM) :**\n",
    "- **Meilleures performances** : Surtout sur des tâches complexes\n",
    "- **Contexte bidirectionnel** : BERT comprend le contexte dans les deux directions\n",
    "- **Transfer Learning** : Modèles pré-entraînés réutilisables\n",
    "- **Scalabilité** : Fonctionne bien avec de grandes quantités de données\n",
    "\n",
    "**Par rapport aux RNN/LSTM :**\n",
    "- **Parallélisation** : Entraînement plus rapide\n",
    "- **Long-range dependencies** : Meilleure capture des dépendances à long terme\n",
    "- **Attention mechanism** : Comprend quelles parties du texte sont importantes\n",
    "\n",
    "### 13.2. Inconvénients et Limitations\n",
    "\n",
    "- **Coût computationnel** : Plus lent et gourmand en mémoire que les méthodes classiques\n",
    "- **Données d'entraînement** : Nécessite beaucoup de données pour le pré-entraînement\n",
    "- **Interprétabilité** : Plus difficile à interpréter qu'un modèle linéaire\n",
    "- **Taille des modèles** : Modèles très volumineux (millions de paramètres)\n",
    "\n",
    "### 13.3. Quand Utiliser les Transformers ?\n",
    "\n",
    "**Utilisez les transformers si :**\n",
    "- Vous avez accès à des ressources computationnelles suffisantes\n",
    "- Vous travaillez sur des tâches complexes (traduction, QA, etc.)\n",
    "- Vous avez des données textuelles abondantes\n",
    "- La performance est critique\n",
    "\n",
    "**Utilisez des méthodes classiques si :**\n",
    "- Vous avez des contraintes de ressources\n",
    "- Votre dataset est petit\n",
    "- Vous avez besoin d'interprétabilité\n",
    "- Les performances acceptables sont suffisantes\n",
    "\n",
    "### 13.4. Modèles Recommandés\n",
    "\n",
    "- **Pour classification de texte** : DistilBERT (rapide) ou BERT (plus précis)\n",
    "- **Pour génération de texte** : GPT-2, GPT-3\n",
    "- **Pour traduction** : mBART, T5\n",
    "- **Pour question answering** : BERT, RoBERTa\n",
    "- **Pour embeddings** : Sentence-BERT\n",
    "\n",
    "### 13.5. Prochaines Étapes\n",
    "\n",
    "1. **Optimisation** : Hyperparameter tuning (learning rate, batch size, epochs)\n",
    "2. **Data Augmentation** : Back-translation, synonym replacement\n",
    "3. **Ensemble Methods** : Combiner plusieurs modèles\n",
    "4. **Domain Adaptation** : Fine-tuning sur un domaine spécifique\n",
    "5. **Model Compression** : Quantization, distillation pour déploiement\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Exercices Complémentaires (Optionnel)\n",
    "\n",
    "### Exercice 1 : Fine-tuning sur un Autre Dataset\n",
    "- Téléchargez un autre dataset de classification (ex: AG News, 20 Newsgroups)\n",
    "- Fine-tunez DistilBERT ou BERT sur ce nouveau dataset\n",
    "- Comparez les performances avec notre modèle actuel\n",
    "\n",
    "### Exercice 2 : Hyperparameter Tuning\n",
    "- Testez différents learning rates (1e-5, 2e-5, 5e-5)\n",
    "- Variez la taille des batches (8, 16, 32)\n",
    "- Testez différents nombres d'epochs\n",
    "- Identifiez les meilleurs hyperparamètres\n",
    "\n",
    "### Exercice 3 : Comparaison de Modèles\n",
    "- Comparez BERT, DistilBERT, et RoBERTa sur la même tâche\n",
    "- Mesurez le temps d'entraînement et les performances\n",
    "- Analysez les trade-offs\n",
    "\n",
    "### Exercice 4 : Analyse de l'Attention\n",
    "- Visualisez les weights d'attention pour comprendre ce sur quoi le modèle se concentre\n",
    "- Comparez l'attention entre différents exemples\n",
    "- Interprétez les patterns d'attention\n",
    "\n",
    "### Exercice 5 : Multi-class Classification\n",
    "- Adaptez le modèle pour une classification multi-classes (3+ classes)\n",
    "- Utilisez un dataset comme AG News ou 20 Newsgroups\n",
    "- Comparez avec des approches classiques\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
